{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPy/+x/MIoOfJ012NOJic5K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ed765super/DATA602-Baltimore-Employee-Data-Classification/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_bvGhz2fpf8",
        "outputId": "ae970f45-88ac-44fa-dafa-0ffda7c2fa36"
      },
      "source": [
        "import pandas as pd\n",
        "#https://www.kaggle.com/aashofteh/train-dataset-kaggle-credit-scoring-1\n",
        "df = pd.read_csv('Baltimore_City_Employee_Salaries.csv', sep=',')\n",
        "print(df.info())\n",
        "print(df.describe(include='all'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 154187 entries, 0 to 154186\n",
            "Data columns (total 11 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   lastName       153777 non-null  object \n",
            " 1   middleInitial  121195 non-null  object \n",
            " 2   firstName      154187 non-null  object \n",
            " 3   jobClass       154003 non-null  object \n",
            " 4   agencyName     154187 non-null  object \n",
            " 5   agencyID       154187 non-null  object \n",
            " 6   annualSalary   154187 non-null  float64\n",
            " 7   grossPay       154187 non-null  float64\n",
            " 8   hireDate       154185 non-null  object \n",
            " 9   fiscalYear     154187 non-null  object \n",
            " 10  ObjectId       154187 non-null  int64  \n",
            "dtypes: float64(2), int64(1), object(8)\n",
            "memory usage: 12.9+ MB\n",
            "None\n",
            "       lastName middleInitial firstName  ...    hireDate fiscalYear       ObjectId\n",
            "count    153777        121195    154187  ...      154185     154187  154187.000000\n",
            "unique    11645            61      6890  ...        6930         11            NaN\n",
            "top     Johnson             A   Michael  ...  2007-06-23     FY2020            NaN\n",
            "freq       2345         15838      3416  ...         738      16653            NaN\n",
            "mean        NaN           NaN       NaN  ...         NaN        NaN   77094.000000\n",
            "std         NaN           NaN       NaN  ...         NaN        NaN   44510.097315\n",
            "min         NaN           NaN       NaN  ...         NaN        NaN       1.000000\n",
            "25%         NaN           NaN       NaN  ...         NaN        NaN   38547.500000\n",
            "50%         NaN           NaN       NaN  ...         NaN        NaN   77094.000000\n",
            "75%         NaN           NaN       NaN  ...         NaN        NaN  115640.500000\n",
            "max         NaN           NaN       NaN  ...         NaN        NaN  154187.000000\n",
            "\n",
            "[11 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4C0d-WFaV93"
      },
      "source": [
        "#Background Information/Buisness Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gktDE1Wja3QF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxU8OftjaeQz"
      },
      "source": [
        "#EDA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0FdFMYKbQe1"
      },
      "source": [
        "I will start by checking whether any of my features have null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNAdUVRNa3uz"
      },
      "source": [
        "print(df.isna().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgHm13LQcHOc"
      },
      "source": [
        "df = df.query('[TARGET VARIABLE].notna()', engine='python')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm6vhlkdbiGs"
      },
      "source": [
        "Next I will check the 5 number summary for each of my features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrMkpXDAbE6M"
      },
      "source": [
        "df.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKljo9BSbr-b"
      },
      "source": [
        "Next I will gather a visual summary of my data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xJFJurabG7k"
      },
      "source": [
        "df.hist(figsize=(14,14))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxZVvvQ6bJ0q"
      },
      "source": [
        "Next I'll check for any multicoliniarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeDnvQGSbJDT"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.heatmap(df.corr())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZG8-N2JaiJL"
      },
      "source": [
        "#Data cleaning and Feature engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Lkg7OU8a4Nl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxtsn0h1aoNe"
      },
      "source": [
        "#Modeling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suO5ZiHcb05a"
      },
      "source": [
        "####Splitting Training and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCBMCRdla4o-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "curr_Random_State = 50\n",
        "\n",
        "feature_names = df.columns[:-1]\n",
        "#The :-1 excludes the last column which is the target column.\n",
        "\n",
        "#Pre:\n",
        "#X = a valid index list representing columns\n",
        "#y = a valid column representing the target cass\n",
        "#state = a positive numeric integer representing the current \"random state\"\n",
        "#Post: returns two sets of training-test splits.\n",
        "def create_splits(x, y, state):\n",
        "    return (train_test_split(x, y, test_size=.25, random_state = state)\n",
        "    )\n",
        "tX_training, tX_test, ty_training, ty_test = create_splits(df[feature_names], df['Class'], curr_Random_State)\n",
        "print(f'Training samples: {tX_training.shape[0]}')\n",
        "print(f'Test samples: {tX_test.shape[0]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK0z5EWGcWfG"
      },
      "source": [
        "Now I will fit Fit a logistic regression, decision tree, and SVM using grid search\n",
        "\n",
        "First I will set up the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtJEhao0cVpM"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#First grab all the columns and put em in lists\n",
        "nums = df.dtypes[df.dtypes != 'object'].index.tolist()\n",
        "cats = df.dtypes[df.dtypes == 'object'].index.tolist()\n",
        "\n",
        "#Now remove the columns I dont think I need\n",
        "nums = [x for x in nums if x not in ['arr_delay']]\n",
        "cats = [x for x in cats if x not in ['tailnum']]\n",
        "\n",
        "num_pipeline = Pipeline([('impute_missing', SimpleImputer(strategy='median')),\n",
        "                           ('standardize_num', StandardScaler())\n",
        "                        ])\n",
        "\n",
        "cat_pipeline = Pipeline([('impute_missing_cats', SimpleImputer(strategy='most_frequent')),\n",
        "                          ('create_dummies_cats', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "processing_pipeline = ColumnTransformer(transformers=[('proc_numeric', num_pipeline, nums),\n",
        "                                                      ('create_dummies', cat_pipeline, cats)])\n",
        "\n",
        "print('Pipeline Created')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sod16MxJc6ZV"
      },
      "source": [
        "Logistic Regression with grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZQ49WFqc4Tr",
        "outputId": "84a01b02-1bf8-491c-d065-6cd432339439"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "import time\n",
        "start_time = time.time()\n",
        "p1 = Pipeline([('processing', processing_pipeline),\n",
        "             ('lr', LogisticRegression(solver='liblinear'))])\n",
        "\n",
        "#Select various correlation strengths with a magnitude of 10\n",
        "params = {'lr__C': [.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "#I will score based on accurancy as that the dataset is not heavily skewed\n",
        "lr_gscv = GridSearchCV(p1, param_grid=params, cv=10, scoring='accuracy', refit=True)\n",
        "\n",
        "lr_gscv = lr_gscv.fit(tX_train, ty_train)\n",
        "\n",
        "print(f'Validation score: {lr_gscv.best_score_:.2%}')\n",
        "\n",
        "lr_pred = lr_gscv.predict(tX_test)\n",
        "\n",
        "print(f'Test score: {lr_gscv.score(tX_test, ty_test):.2%}')\n",
        "print (\"Runtime: \", time.time() - start_time, \" seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 68.77%\n",
            "Test score: 67.68%\n",
            "Runtime:  13.320276260375977  seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rt1Xkzzd0se"
      },
      "source": [
        "Descision Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvENq38Kdz6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d593f6ea-e695-4c3b-d89a-43719ea01e0b"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "p2 = Pipeline([('processing', processing_pipeline),\n",
        "             ('dt', DecisionTreeClassifier())])\n",
        "\n",
        "params = {'dt__max_depth': [1, 5, 10, 15, 25],\n",
        "         'dt__min_samples_split': [3, 10, 15]}\n",
        "\n",
        "dt_gscv = GridSearchCV(p2, param_grid=params, cv=10, scoring='accuracy', refit=True)\n",
        "dt_gscv = dt_gscv.fit(tX_train, ty_train)\n",
        "\n",
        "print(f'Validation score: {dt_gscv.best_score_:.2%}')\n",
        "\n",
        "dt_pred = dt_gscv.predict(tX_test)\n",
        "\n",
        "print(f'Test score: {dt_gscv.score(tX_test, ty_test):.2%}')\n",
        "print (\"Runtime: \", time.time() - start_time, \" seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 64.59%\n",
            "Test score: 62.70%\n",
            "Runtime:  43.282294034957886  seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9wUS3bFd2ks"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg5rtfCPeStD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf7dc37-a8ec-44e2-9bb7-560cd35f4193"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import time\n",
        "start_time = time.time()\n",
        "svm_m = modeling_pipeline = Pipeline([('processing', processing_pipeline),\n",
        "                                      ('scaling', StandardScaler(with_mean=False)),\n",
        "                                       ('model', SVC())])\n",
        "\n",
        "\n",
        "param_grid = [\n",
        "  {'model__C': [0.1, 1, 10, 100], 'model__kernel': ['rbf']}\n",
        " ]\n",
        "\n",
        "svm_results = GridSearchCV(estimator=svm_m, param_grid=param_grid, cv=10, scoring='accuracy', refit=True)\n",
        "svm_results = svm_results.fit(tX_train, ty_train)\n",
        "\n",
        "print(f'Validation score: {svm_results.best_score_:.2%}')\n",
        "\n",
        "svm_pred = svm_results.predict(tX_test)\n",
        "\n",
        "print(f'Test score: {svm_results.score(tX_test, ty_test):.2%}')\n",
        "print (\"Runtime: \", time.time() - start_time, \" seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 64.92%\n",
            "Test score: 65.09%\n",
            "Runtime:  195.7040295600891  seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weqkwJGUarpe"
      },
      "source": [
        "#Results and discussion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRbsFiCyWuyD"
      },
      "source": [
        "#Fit an ensemble using the three above models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGRkOMP4fzyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e92358-96ec-4697-f3c4-0e9960792d7c"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "clf1 = LogisticRegression(penalty='l2', C=0.001, solver='lbfgs', random_state=0)\n",
        "clf2 = DecisionTreeClassifier(max_depth=1, criterion='entropy', random_state=1)\n",
        "clf3 = svm.SVC(probability=True)\n",
        "\n",
        "pipe1 = Pipeline([('processing', processing_pipeline),\n",
        "             ('lr', LogisticRegression(solver='liblinear'))])\n",
        "pipe2 = Pipeline([('processing', processing_pipeline),\n",
        "             ('dt', DecisionTreeClassifier())])\n",
        "pipe3 = Pipeline([('processing', processing_pipeline),\n",
        "                ('scaling', StandardScaler(with_mean=False)),\n",
        "                ('model', SVC())])\n",
        "\n",
        "labs = ['Logistic Regression', 'Decision Tree', 'Support Vector Machine']\n",
        "clfs = [pipe1, pipe2, pipe3]\n",
        "clfs = zip(labs, clfs)\n",
        "\n",
        "for lab, clf in clfs:\n",
        "    scores = cross_val_score(estimator=clf, X=tX_train, y=ty_train, cv=10, scoring='accuracy')\n",
        "    print(f'Accuracy {scores.mean():.2f} (+/- {scores.std():.2f}) [{lab}]')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.68 (+/- 0.02) [Logistic Regression]\n",
            "Accuracy 0.59 (+/- 0.02) [Decision Tree]\n",
            "Accuracy 0.63 (+/- 0.01) [Support Vector Machine]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9IYo87af1Gy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7766df9-711e-4a67-bd1f-2847c84c956e"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "ems = [('lr', pipe1),('dt', pipe2),('model', pipe3)]\n",
        "#Changing voting to hard because SVM doesnt use probabilities\n",
        "#so using the mode is ok\n",
        "clf4 = VotingClassifier(estimators= ems, weights=None, voting='hard')\n",
        "\n",
        "scores = cross_val_score(estimator=clf4, X=tX_train, y=ty_train, cv=10, scoring='accuracy')\n",
        "print(f'Accuracy {scores.mean():.2f} (+/- {scores.std():.2f}) [Ensemble]')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.66 (+/- 0.01) [Ensemble]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYwmGU3td7-c"
      },
      "source": [
        "ADA BOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As3EEQHDd7Kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a911635-2da1-4b6c-df73-8f8ea34f3281"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "import time\n",
        "start_time = time.time()\n",
        "# multi-step pipelines don't play as nice with AdaBoost\n",
        "xt = processing_pipeline.fit_transform(tX_train)\n",
        "\n",
        "params = {'n_estimators': [50, 100, 200, 500, 1000]\n",
        "         }\n",
        "\n",
        "#ABC = AdaBoostClassifier(base_estimator=p2)\n",
        "ABC = AdaBoostClassifier(DecisionTreeClassifier())\n",
        "\n",
        "\n",
        "ad_gscv = GridSearchCV(ABC, param_grid = params, cv=10, scoring='accuracy')\n",
        "           \n",
        "ad_gscv = ad_gscv.fit(xt, ty_train)\n",
        "\n",
        "print(f'Validation score: {ad_gscv.best_score_:.2%}')\n",
        "\n",
        "xtt = processing_pipeline.transform(tX_test)\n",
        "\n",
        "ad_pred = ad_gscv.predict(xtt)\n",
        "\n",
        "print(f'Test score: {ad_gscv.score(xtt, ty_test):.2%}')\n",
        "print (\"Runtime: \", time.time() - start_time, \" seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 58.57%\n",
            "Test score: 58.34%\n",
            "Runtime:  23.792025566101074  seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSJHarB0WsKt"
      },
      "source": [
        "#Discuss the performance of each model.\n",
        "* Logistic Regression had the highest accuracy score and took the least amount of time to run\n",
        "* SVM took the longest despite searching over less correlation strengths. This is most likely due to the immense ammount of copies being created during SVM\n",
        "* Descision Trees had the lowest accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEI22OU_a5BR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n13atavYavs_"
      },
      "source": [
        "#Conclusion/next steps\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J9AO1kEa5fT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn17nmnsaywu"
      },
      "source": [
        "#References"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k4kIzmga6IP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}